\chapter{Обзор предметной области}
\label{chapter1}

\section{Эволюционные алгоритмы}
\label{evo_algs}

\subsection{Основные принципы}
\textit{Эволюционные алгоритмы} применяются для решения задач оптимизации и используют механизмы, 
основанные на принципах природной эволюции.\cite{petrova_evo1} 

Эволюционные алгоритмы работают с множеством \textit{особей}-кандидатов на оптимальное решение. 
Как правило, особи представляются в виде точек в $K$-мерном пространстве, где $K$ - количество 
оптимизируемых критериев особи. Целью работы эволюционного алгоритма является нахождение наиболее 
приспособленной особи.

Функция, позволяющая оценить приспособленность особи, называется \textit{функцией приспособленности}.
В задачах многокритериальной оптимизации требуется рассматривать несколько функций приспособленности.

Каждая итерация эволюционного алгоритма работает с \textit{поколением} особей. Особи следующего 
поколения генерируются путем применения к особям текущего поколения операторов скрещивания, 
мутации и отбора.

В результате работы каждой итерации эволюционного алгоритма формируется множество особей следующего 
поколения, которое будет оптимизироваться следующей итерацией эволюционного алгоритма. Как правило, 
размер поколения фиксирован, поэтому в конце каждой итерации наименее приспособленные особи 
отбрасываются.

Эволюционный алгоритм завершает работу, как только достигнуто хотя бы одно из условий останова.
Как правило, в качестве критериев останова используется число итераций, либо значения функций
приспособленности.

\subsection{Популярные реализации}
\subsubsection{NSGA}
Алгоритм \textit{NSGA (Nondominated Sorting Genetic Algorithm)} является одним из первых алгоритмов
многокритериальной оптимизации. \cite{deb_nsga2}

Данный алгоритм на каждой итерации выполняет недоминирующую сортировку за $O(KN^3)$.
Помимо значений функции приспособленности, в качестве критерия перехода особи в следующую популяцию
используется \textit{фенотипическая дистанция}: если дистанция до какой-либо особи из следующего 
поколения меньше, чем задано параметром, то текущая особь в следующее поколение не добавляется. 
\cite{nsga1}

У данного алгоритма есть следующие недостатки: \cite{deb_nsga2}
\begin{enumerate}
\item Высокая вычислительная сложность недоминирующей сортировки;
\item Необходимость подбора параметра, определяющего минимально допустимое фенотипическое
	расстояние между особями;
\item Отсутствие элитизма.
\end{enumerate}

\subsubsection{Классический NSGA-II}
Алгоритм NSGA-II призван исправить основные недостатки алгоритма NSGA: \cite{deb_nsga2}
\begin{enumerate}
\item Сортировка выполняется за $O(KN^2)$;
\item При формировании нового поколения используются лучшие особи как из модифицированной
	(т. е. полученной в результате мутации и скрещивания особей текущего поколения) 
	популяции, так и из исходной;
\item При формировании нового поколения из комбинированной популяции отбрасываются особи
	с наибольшим рангом. Если в популяции остается только часть особей с некоторым рангом,
	выбираются особи с наибольшей \textit{crowding distance} - средней длиной ребра кубоида,
	образованного соседними особями (для крайних особей этот показатель равен $\infty$).
\end{enumerate}

Несмотря на это, у данного алгоритма есть недостаток, свойственный всем \textit{классическим}
(т. е. оперирующим поколениями особей) алгоритмам - невозможность эффективного распараллеливания.
Перед тем, как пересчитать ранг особи, алгоритм должен завершить расчет функций приспособленности 
всех особей. Решить данную проблему призваны \textit{инкрементальные (steady-state}) алгоритмы.
\cite{max_me_ss_nsga2}

\subsubsection{SPEA-II}
Алгоритм SPEA-II, хотя и позволяет достичь схожих с NSGA-II результатов, не использует процедуру 
недоминирующей сортировки (равно как и ранг точки) в том виде, в каком она используется в NSGA и 
NSGA-II и рассматривается в данной работе.

Для точки определены следующие величины: \cite{spea2}
\begin{enumerate}
 \item \textit{Сила} - число точек, над которыми текущая точка доминирует;
 \item \textit{Исходная жизнеспособность} (англ. \textit{raw fitness}) - сумма сил всех точек, 
	которые доминируют над текущей;
 \item \textit{Плотность} - величина, определяющая расстояние до ближайших точек.
	Данная величина по модулю меньше единицы.
\end{enumerate}

Особи оцениваются по сумме исходной жизнеспособности и плотности.

\subsubsection{Инкрементальные алгоритмы}
Наиболее очевидным способом реализовать инкрементальные версии алгоритмов NSGA-II и SPEA-II
является использование классических (\textit{population-based}) алгоритмов с модифицированной
популяцией размера 1. \cite{inc_nsga2_spea2}

Было отмечено, что инкрементальные версии алгоритмов позволяют получить сравнимый результат
за меньшее число итераций, ценой в 10-20 раз большего времени работы.

Основной причиной низкой производительности является скорость выполнения полной сортировки
множества особей. Лучшие из известных на сегодня алгоритмов позволяют выполнять сортировку 
за $O(Nlog^{K-1}N)$

\section{Алгоритмы недоминирующей сортировки}
\subsection{Алгоритмы полной сортировки}
\subsubsection{NSGA}
Простейшая реализация процедуры недоминирующей сортировки была предложена в рамках алгоритма NSGA.
\cite{nsga1}
\begin{algorithm}[H]
\begin{algorithmic}[1]
\Procedure{NDS\textunderscore NSGA}{$P$}
	\State{$i \gets 0$}
	\While{$P \neq \emptyset$}
		\For{$p \in P$}
			\State{$fDominated \gets false$}
			\For{$p' \in P$}
				\If{$p' \prec p$}
					\State{$fDominated \gets true$}
				\EndIf
			\EndFor
			\If{$!fDominated$}
				\State{$P[i] \gets P[i] \cup p$}
				\State{$P \gets P \setminus p$}
			\EndIf
		\EndFor
		\State{$i \gets i + 1$}
	\EndWhile
\EndProcedure
\end{algorithmic}
\caption{Алгоритм недоминирующей сортировки, входящий в NSGA.}
\label{NDS_NSGA}
\end{algorithm}
Данный алгоритм $O(N)$ раз выполняет поиск всех недоминируемых особей и перемещает 
их на текущий уровень недоминирования, удаляя их из исходной популяции.
Каждый раз поиск недоминируемых особей выполняется за $O(KN^2)$. Итоговое время работы алгоритма
составляет $O(KN^3)$ в худшем случае. \cite{deb_nsga2}

\subsubsection{NSGA-II}
В алгоритме NSGA-II был предложен более эффективный алгоритм сортировки, работающий за $O(KN^2)$
в худшем случае.\cite{deb_nsga2}
\begin{algorithm}[H]
\begin{algorithmic}[1]
\Procedure{NDS\textunderscore NSGA2}{$P$}
	\For{$p \in P$}
		\State{$S_p \gets \emptyset$}
		\State{$n_p \gets 0$}
		\For{$p' \in P$}
			\If{$p \prec p'$}
				\State{$S_p \gets S_p \cup p'$}
			\ElsIf{$p' \prec p$}
				\State{$n_p \gets n_p + 1$}
			\EndIf
		\EndFor
		\If{$n_p = 0$}
			\State{$p_rank \gets 1$}
			\State{$F_1 \gets F_1 \cup p$}
		\EndIf
	\EndFor
	\State{$i \gets 1$}
	\While{$F_i \neq \emptyset$}
		\State{$Q \gets \emptyset$}
		\For{$p \in F_i$}
			\For{$q \in S_p$}
				\State{$n_q \gets n_q - 1$}
				\If{$n_q = 0$}
					\State{$p_rank \gets i + 1$}
					\State{$Q \gets Q \cup q$}
				\EndIf
			\EndFor
		\EndFor
		\State{$i \gets i + 1$}
		\State{$F_i \gets Q$}
	\EndWhile
\EndProcedure
\end{algorithmic}
\caption{Алгоритм недоминирующей сортировки, входящий в NSGA-II.}
\label{NDS_NSGA2}
\end{algorithm}

Первая часть алгоритма (работающая за $O(KN^2)$) находит все недоминируемые точки способом,
аналогичным используемому в алгоритме NSGA. Для каждой точки сохраняется множество точек,
над которыми она доминирует, а также число точек, доминирующих над ней.

На основании этих данных, вторая часть алгоритма распределяет точки (для которых число
доминирующех точек, еще не распределенных по уровням недоминирования, равно нулю) по уровням
недоминирования за $O(KN^2)$).

Итоговое время работы алгоритма - $O(KN^2)$) в худшем случае.

\subsubsection{Быстрые алгоритмы}
Кунгом \textit{с соавт.} (Kung \textit{et al}) \cite{kung} был предложен алгоритм, позволяющий 
выполнять поиск недоминируемых особей за $O(N \log^{K - 1} N)$, где K - размерность пространства, 
и N - размер популяции. Данный алгоритм можно использовать для выполнения недоминирующей сортировки \cite{max_me_ss_nsga2}, 
последовательно находя недоминируемые решения и удаляя их их популяции, но итоговое время работы
алгоритма составит $O(N^2 \log^{K - 1} N)$ в худшем случае.

Дженсеном \textit{с соавт.} (Jensen \textit{et al}) \cite{jensen} был предложен алгоритм, позволяющий 
выполнять недоминирующую сортировку за $O(N \log^{K - 1} N)$ в худшем случае, исходя из предположения,
что для любых двух точек ни одна из координат не может оказаться одинаковой.

Наконец, Буздалов \textit{с соавт.} модифицировали алгоритм Дженсена таким образом, чтобы
время работы в худшем случае составило $O(N \log^{K - 1} N)$ без каких-либо дополнительных ограничений
на значения точек \cite{max_sort}.

\subsection{Алгоритм инкрементальной сортировки ENLU}
TODO